{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dd3fa4b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "pip install finta"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "d553a552",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql import SparkSession\n",
    "import findspark\n",
    "import pandas as pd\n",
    "findspark.init()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "af27118b",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: An illegal reflective access operation has occurred\n",
      "WARNING: Illegal reflective access by org.apache.spark.unsafe.Platform (file:/usr/local/spark-3.1.2-bin-hadoop3.2/jars/spark-unsafe_2.12-3.1.2.jar) to constructor java.nio.DirectByteBuffer(long,int)\n",
      "WARNING: Please consider reporting this to the maintainers of org.apache.spark.unsafe.Platform\n",
      "WARNING: Use --illegal-access=warn to enable warnings of further illegal reflective access operations\n",
      "WARNING: All illegal access operations will be denied in a future release\n",
      "22/01/06 14:45:20 WARN NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable\n",
      "Using Spark's default log4j profile: org/apache/spark/log4j-defaults.properties\n",
      "Setting default log level to \"WARN\".\n",
      "To adjust logging level use sc.setLogLevel(newLevel). For SparkR, use setLogLevel(newLevel).\n"
     ]
    }
   ],
   "source": [
    "from pyspark.sql import SparkSession\n",
    "\n",
    "# Spark session & context\n",
    "spark = (SparkSession\n",
    "         .builder\n",
    "         .master(\"local\")\n",
    "         .appName(\"raw-dataset\")\n",
    "         # Add postgres jar\n",
    "         .config(\"spark.driver.extraClassPath\", \"/home/jovyan/work/jars/postgresql-9.4.1207.jar\")\n",
    "         .getOrCreate())\n",
    "sc = spark.sparkContext"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "fe70f029",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "df = spark.read.options(header='True',inferSchema='True',delimiter=',').csv('/home/jovyan/work/data/dataset/raw.csv')\n",
    "df = df.drop(df[0]) #drop index column (first column)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "1cb2c766",
   "metadata": {},
   "outputs": [],
   "source": [
    "##reanme column to match Finta API require\n",
    "import pyspark.sql.functions as F\n",
    "columns = {\"Close\": 'close', \"High\": 'high', \"Low\": 'low', 'Volume': 'volume', 'Open': 'open'}\n",
    "\n",
    "def rename_columns(df, columns):\n",
    "    if isinstance(columns, dict):\n",
    "        return df.select(*[F.col(col_name).alias(columns.get(col_name, col_name)) for col_name in df.columns])\n",
    "    else:\n",
    "        raise ValueError(\"'columns' should be a dict, like {'old_name_1':'new_name_1', 'old_name_2':'new_name_2'}\")\n",
    "\n",
    "df = rename_columns(df,columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "266a7414",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "from pyspark.sql.functions import to_timestamp\n",
    "df = df.withColumn(\"Date\",to_timestamp(df.Date))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "287d92b2",
   "metadata": {},
   "outputs": [],
   "source": [
    "def _get_indicator_grouped_data(key, group):\n",
    "    from finta import TA\n",
    "    INDICATORS = ['RSI', 'STOCH','ADL', 'ATR', 'MOM', 'MFI', 'ROC', 'OBV', 'CCI', 'EMV','WILLIAMS','ADX', 'TRIX']\n",
    "    \n",
    "    #df = pd.DataFrame()\n",
    "    ind = pd.DataFrame()\n",
    "    for indicator in INDICATORS:\n",
    "        ind_data = eval('TA.' + indicator + '(group)')\n",
    "        if not isinstance(ind_data,pd.DataFrame):\n",
    "            ind_data = ind_data.to_frame()\n",
    "            group = group.merge(ind_data, left_index=True, right_index=True)\n",
    "\n",
    "    del (group['open'])\n",
    "    del (group['high'])\n",
    "    del (group['low'])\n",
    "    del (group['volume'])\n",
    "    del (group['Adj Close'])\n",
    "    \n",
    "    #uncomment 2 lines below to test return column\n",
    "    #print(group.columns)\n",
    "    #return pd.DataFrame([key]) \n",
    "    \n",
    "    return pd.DataFrame(group.values)\n",
    "\n",
    "#SCHEMA = \"key string\"  test schema\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "3c6d41e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Schema have to match with return dataframe. Check group.columns, some of indicators maybe return null \n",
    "SCHEMA = \"Date date, close double, symbol string, 14_period_RSI double, \\\n",
    "14_period_STOCH_K double, MFV double, 14_period_ATR double, MOM double, 14_period_MFI double, \\\n",
    "ROC double, OBV double, 20_period_CCI double, 14_period_EMV double, Williams double, 14_period_ADX double, 20_period_TRIX double\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "18388aa0",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_indi = df.groupBy(\"Symbol\").applyInPandas(_get_indicator_grouped_data,schema=SCHEMA)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "ef97e7ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "def _produce_prediction(group):\n",
    "    \"\"\"\n",
    "    Function that produces the 'truth' values\n",
    "    At a given row, it looks 'day' rows ahead to see if the price increased (1) or decreased (0)\n",
    "    :param day: number of days, or rows to look ahead to see what the price did\n",
    "    \"\"\"\n",
    "    day = [3,5,7,10]\n",
    "    for d in day:\n",
    "        prediction = (group.shift(-d)['close'] >= group['close'])\n",
    "        prediction = prediction.iloc[:-d]\n",
    "        group['pred_'+str(d)] = prediction.astype(int)\n",
    "        group.dropna(inplace=True)\n",
    "    \n",
    "    return pd.DataFrame(group.values)\n",
    "\n",
    "#data = _produce_prediction(group)\n",
    "#del (data['close'])\n",
    "#data = data.dropna() # Some indicators produce NaN values for the first few rows, we just remove them here\n",
    "#data.tail()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "544d59d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Schema have to match with return dataframe. Check group.columns, some of indicators maybe return null \n",
    "SCHEMA_PREDICTION = \"Date date, close double, symbol string, 14_period_RSI double, \\\n",
    "14_period_STOCH_K double, MFV double, 14_period_ATR double, MOM double, 14_period_MFI double, \\\n",
    "ROC double, OBV double, 20_period_CCI double, 14_period_EMV double, Williams double, 14_period_ADX double, 20_period_TRIX double,\\\n",
    "pred_3 int, pred_5 int, pred_7 int, pred_10 int\"\n",
    "\n",
    "df_prediction = df_indi.groupBy(\"Symbol\").applyInPandas(_produce_prediction,schema=SCHEMA_PREDICTION)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "644399b0",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "df_prediction.coalesce(1).write.csv ('/home/jovyan/work/data/dataset_final',header=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cc8f91a7",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
